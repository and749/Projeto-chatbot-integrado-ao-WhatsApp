{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMpQG7+ROKyx8fSvwZAxiCa",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/and749/Projeto-de-imers-o-para-o-certificado/blob/main/Chat_bot_inicial_integra%C3%A7%C3%A3o_WhastApp.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Instalando o SDK do google"
      ],
      "metadata": {
        "id": "Y7w5QiuAGwJo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import google.generativeai as genai\n",
        "from google.colab import userdata\n",
        "api_key = userdata.get('secret_key')\n",
        "GOOGLE_API_KEY=\"secret_key\"\n",
        "genai.configure(api_key=api_key)\n"
      ],
      "metadata": {
        "id": "6DrlbJZCGkTp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Listar os modelos disponíveis"
      ],
      "metadata": {
        "id": "hONXnp-kGsuV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for m in genai.list_models():\n",
        "  if 'generateContent' in m.supported_generation_methods:\n",
        "    print(m.name)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 138
        },
        "id": "sB7wt8KBGp2j",
        "outputId": "27cb60a6-e885-4b04-cc89-976a8c8796c0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "models/gemini-1.0-pro\n",
            "models/gemini-1.0-pro-001\n",
            "models/gemini-1.0-pro-latest\n",
            "models/gemini-1.0-pro-vision-latest\n",
            "models/gemini-1.5-pro-latest\n",
            "models/gemini-pro\n",
            "models/gemini-pro-vision\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "generation_config = {\n",
        "    \"candidate_count\": 1,\n",
        "    \"temperature\": 0.5\n",
        "}"
      ],
      "metadata": {
        "id": "lwhmKf8bHeN1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "safety_settings = {\n",
        "\t\"HARASSMENT\": \"BLOCK_NONE\" ,\n",
        "\t\"HATE\" : \"BLOCK_NONE\" ,\n",
        "\t\"SEXUAL\": \"BLOCK_NONE\" ,\n",
        "\t\"DANGEROUS\": \"BLOCK_NONE\",\n",
        "}"
      ],
      "metadata": {
        "id": "qHOEoXGZLZG0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Inicializando modelo"
      ],
      "metadata": {
        "id": "ddW72o7UMhXA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = genai.GenerativeModel(model_name=\"gemini-1.0-pro\" ,\n",
        "generation_config=generation_config,\n",
        "safety_settings=safety_settings)"
      ],
      "metadata": {
        "id": "KbGOlYQWMMgy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "response = model.generate_content(\"vamos aprender conteúdo sobre IA, me de sugestões\")\n",
        "print(response.text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 694
        },
        "id": "pTeSws9lORFu",
        "outputId": "f96bba7a-a2a7-4d0e-dee9-25f07157f83a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "**Recursos Online:**\n",
            "\n",
            "* **Coursera:** Cursos sobre IA, aprendizado de máquina e aprendizado profundo\n",
            "* **edX:** Cursos sobre IA, ciência de dados e engenharia de software\n",
            "* **MIT OpenCourseWare:** Cursos sobre IA, aprendizado de máquina e processamento de linguagem natural\n",
            "* **Google AI Education:** Tutoriais, cursos e recursos sobre IA e aprendizado de máquina\n",
            "* **Microsoft Learn:** Cursos e módulos sobre IA, aprendizado de máquina e ciência de dados\n",
            "\n",
            "**Livros:**\n",
            "\n",
            "* **Inteligência Artificial: Uma Abordagem Moderna (3ª edição)** por Stuart Russell e Peter Norvig\n",
            "* **Aprendizado de Máquina (4ª edição)** por Ethem Alpaydin\n",
            "* **Aprendizado Profundo** por Ian Goodfellow, Yoshua Bengio e Aaron Courville\n",
            "* **IA para Todos** por Andrew Ng\n",
            "* **Inteligência Artificial: Uma Introdução** por Melanie Mitchell\n",
            "\n",
            "**Revistas e Publicações:**\n",
            "\n",
            "* **Nature Machine Intelligence:** Revista científica sobre IA e aprendizado de máquina\n",
            "* **IEEE Transactions on Neural Networks and Learning Systems:** Publicação técnica sobre redes neurais e sistemas de aprendizado\n",
            "* **ACM Transactions on Intelligent Systems and Technology:** Publicação técnica sobre sistemas inteligentes e tecnologia\n",
            "* **AI Magazine:** Revista da Association for the Advancement of Artificial Intelligence (AAAI)\n",
            "* **MIT Technology Review:** Revista sobre as últimas tendências em tecnologia, incluindo IA\n",
            "\n",
            "**Eventos e Conferências:**\n",
            "\n",
            "* **Conferência Internacional sobre Aprendizado de Máquina (ICML)**\n",
            "* **Conferência Internacional sobre Inteligência Artificial (IJCAI)**\n",
            "* **Conferência sobre Sistemas de Processamento de Informação Neural (NeurIPS)**\n",
            "* **Conferência sobre Visão Computacional e Reconhecimento de Padrões (CVPR)**\n",
            "* **Conferência sobre Processamento de Linguagem Natural (ACL)**\n",
            "\n",
            "**Comunidades e Fóruns Online:**\n",
            "\n",
            "* **Stack Overflow:** Fórum de perguntas e respostas sobre programação e IA\n",
            "* **Reddit:** Subreddits dedicados a IA, aprendizado de máquina e aprendizado profundo\n",
            "* **Discord:** Servidores dedicados a comunidades de IA e aprendizado de máquina\n",
            "* **Slack:** Grupos de trabalho e canais de discussão sobre IA\n",
            "* **LinkedIn:** Grupos e fóruns sobre IA e tecnologias relacionadas\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "chat = model.start_chat(history=[])"
      ],
      "metadata": {
        "id": "KLV0Z7RVOaId"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = input(\"esperando prompt: \")\n",
        "\n",
        "while prompt != \"fim\" :\n",
        "  response = chat.send_message(prompt)\n",
        "  print(\"resposta \" , response.text, \"\\n\")\n",
        "  prompt = input(\"esperando prompt: \")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 191
        },
        "id": "lGuCBu83PJ8D",
        "outputId": "1083a387-96ed-43ee-8e8e-a4e8b9723a78"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "esperando prompt: qual foi a primeira noticia que vimos hoje?\n",
            "resposta  Como um assistente de IA, não tenho acesso a informações em tempo real e, portanto, não posso fornecer a primeira notícia que você viu hoje. \n",
            "\n",
            "esperando prompt: Qual foi o primeiro titulo de noticia que eu te encaminhei\n",
            "resposta  Como um assistente de IA, não tenho acesso a informações pessoais ou mensagens privadas, incluindo títulos de notícias que você possa ter me encaminhado. \n",
            "\n",
            "esperando prompt: qual a capital do japão?\n",
            "resposta  Tóquio \n",
            "\n",
            "esperando prompt: fim\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Melhorando a visualização\n",
        "#Código disponível em https://ai.google.dev/tutorials/python_quickstart#import_packages\n",
        "import textwrap\n",
        "from IPython.display import display\n",
        "from IPython.display import Markdown\n",
        "\n",
        "def to_markdown(text):\n",
        "  text = text.replace('•', '  *')\n",
        "  return Markdown(textwrap.indent(text, '> ', predicate=lambda _: True))\n",
        "\n",
        "#Imprimindo o histórico\n",
        "for message in chat.history:\n",
        "  display(to_markdown(f'**{message.role}**: {message.parts[0].text}'))\n",
        "  print('-------------------------------------------')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 428
        },
        "id": "kzxPJLU9SS5q",
        "outputId": "127bd19c-3481-40d6-9db6-add594866509"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "> **user**: qual foi a primeira noticia que vimos hoje?"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-------------------------------------------\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "> **model**: Como um assistente de IA, não tenho acesso a informações em tempo real e, portanto, não posso fornecer a primeira notícia que você viu hoje."
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-------------------------------------------\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "> **user**: Qual foi o primeiro titulo de noticia que eu te encaminhei"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-------------------------------------------\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "> **model**: Como um assistente de IA, não tenho acesso a informações pessoais ou mensagens privadas, incluindo títulos de notícias que você possa ter me encaminhado."
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-------------------------------------------\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "> **user**: qual a capital do japão?"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-------------------------------------------\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "> **model**: Tóquio"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q -U google-generativeai twilio flask\n",
        "\n",
        "import os\n",
        "import google.generativeai as genai\n",
        "from flask import Flask, request\n",
        "from twilio.twiml.messaging_response import MessagingResponse\n",
        "\n",
        "# Configurar a API do Google Generative AI\n",
        "GOOGLE_API_KEY = \"SUA_API_KEY\" # **SUBSTITUA pela sua chave API**\n",
        "genai.configure(api_key=GOOGLE_API_KEY)\n",
        "\n",
        "# Configurar as credenciais da Twilio (variáveis de ambiente)\n",
        "os.environ[\"TWILIO_ACCOUNT_SID\"] = \"ACxxxxxxxxxxxxxxxxxxxxxxxxxxxxx\" # **SUBSTITUA pelo seu Account SID**\n",
        "os.environ[\"TWILIO_AUTH_TOKEN\"] = \"your_auth_token\" # **SUBSTITUA pelo seu Auth Token**\n",
        "\n",
        "# Carregar as credenciais da Twilio das variáveis de ambiente\n",
        "TWILIO_ACCOUNT_SID = os.environ.get(\"TWILIO_ACCOUNT_SID\")\n",
        "TWILIO_AUTH_TOKEN = os.environ.get(\"TWILIO_AUTH_TOKEN\")\n",
        "\n",
        "# Criar o aplicativo Flask\n",
        "app = Flask(__name__)\n",
        "\n",
        "# Configurar o modelo Gemini\n",
        "model = genai.GenerativeModel(\n",
        "    model_name=\"gemini-1.0-pro\",\n",
        "    generation_config={\"candidate_count\": 1, \"temperature\": 0.5},\n",
        "    safety_settings={\n",
        "        \"HARASSMENT\": \"BLOCK_NONE\",\n",
        "        \"HATE\": \"BLOCK_NONE\",\n",
        "        \"SEXUAL\": \"BLOCK_NONE\",\n",
        "        \"DANGEROUS\": \"BLOCK_NONE\",\n",
        "    },\n",
        ")\n",
        "chat = model.start_chat(history=[])\n",
        "\n",
        "# Definir a rota do webhook\n",
        "@app.route(\"/webhook\", methods=[\"POST\"])\n",
        "def webhook():\n",
        "    \"\"\"Endpoint para receber mensagens do WhatsApp e enviar respostas.\"\"\"\n",
        "    incoming_msg = request.values.get(\"Body\", \"\").strip()\n",
        "\n",
        "    # Processar a mensagem com o Gemini\n",
        "    response = chat.send_message(incoming_msg)\n",
        "    reply = response.text\n",
        "\n",
        "    # Criar a resposta para Twilio (TwiML)\n",
        "    resp = MessagingResponse()\n",
        "    resp.message(reply)\n",
        "\n",
        "    return str(resp)\n",
        "\n",
        "# Executar o aplicativo Flask (apenas para testes locais)\n",
        "if __name__ == \"__main__\":\n",
        "    app.run(debug=True)"
      ],
      "metadata": {
        "id": "azI-gAA_yaP8"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}